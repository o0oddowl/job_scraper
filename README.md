# Job Scraper: Work.ua & Robota.ua
This project is a web scraper that collects job vacancies from [Work.ua](https://www.work.ua/) and [Robota.ua](https://robota.ua/).  
It enables the collection, storage, and analysis of up-to-date job listings in Ukraine.

---

## ğŸ“„ Data Fields Collected(JSON, CSV):
- **work_title** â€“ job title
- **company** â€“ company name
- **city** â€“ city
- **min_salary** â€“ minimum salary in UAH
- **max_salary** â€“ maximum salary in UAH
- **url** â€“ link to the job vacancy

---

## Output Data (JSON):
```bash
 {
    "work_title": "ĞĞ´Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ñ„Ñ–ÑÑƒ, Ğ¾Ñ„Ñ–Ñ-Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€",
    "company": "ĞšÑ€Ğ°ÑÑĞº Ğ.Ğ’., Ğ¤ĞĞŸ",
    "city": "Ğ¥Ğ°Ñ€ĞºÑ–Ğ²",
    "min_salary": 25000,
    "max_salary": 40000,
    "url": "https://www.work.ua/jobs/6955552/"
}
```

## Output Data (CSV):
```bash
work_title,company_name,city,min_salary,max_salary,url                                                                                                                                                                                 
"ĞĞ´Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ñ„Ñ–ÑÑƒ, Ğ¾Ñ„Ñ–Ñ-Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€","ĞšÑ€Ğ°ÑÑĞº Ğ.Ğ’., Ğ¤ĞĞŸ","Ğ¥Ğ°Ñ€ĞºÑ–Ğ², ",25000,40000,https://www.work.ua/jobs/6955552/
"ĞœĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ· Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ñƒ, Ğ¾Ñ€ĞµĞ½Ğ´Ğ¸ Ğ½ĞµÑ€ÑƒÑ…Ğ¾Ğ¼Ğ¾ÑÑ‚Ñ– (Ğ· Ğ½Ğ°Ğ²Ñ‡Ğ°Ğ½Ğ½ÑĞ¼, ÑÑ‚. Ğ¼. Ğ—Ğ¾Ğ»Ğ¾Ñ‚Ñ– Ğ’Ğ¾Ñ€Ğ¾Ñ‚Ğ°)","Flatprime, ĞĞ","ĞšĞ¸Ñ—Ğ², ",60000,120000,https://www.work.ua/jobs/5976294/
 ĞšĞ°ÑĞ¸Ñ€ Ğ² Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½ Nike,Ğ”ĞµĞ»Ñ‚Ğ° Ğ¡Ğ¿Ğ¾Ñ€Ñ‚,"ĞšĞ¸Ñ—Ğ², ",28000,30000,https://www.work.ua/jobs/6910303/
 Ğ¡Ğ°Ğ´Ñ–Ğ²Ğ½Ğ¸Ğº,TOPIAR,"ĞšĞ¸Ñ—Ğ², ",30000,45000,https://www.work.ua/jobs/6572533/
```

---

## ğŸ“ Project Structure:
```text
job_scraper/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ scraper/
â”‚ â”‚ â”œâ”€â”€ robotaua_scraper.py
â”‚ â”‚ â””â”€â”€ workua_scraper.py
â”‚ â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ robotaua_data.json # Created when script is run
â”‚ â”œâ”€â”€ robotaua_raw_data.csv # Created when script is run
â”‚ â”œâ”€â”€ workua_data.json # Created when script is run
â”‚ â””â”€â”€ workua_raw_data.csv # Created when script is run
â”‚
â”œâ”€â”€ html_file/
â”‚ â””â”€â”€ robotauapage1.html, robotauapage2.html, ..., ~robotauapage5000.html # HTML pages saved by the script
â”‚
â””â”€â”€ requirements.txt
```
---

## âš™ï¸ Requirements:
- Python 3.11
- Firefox (used with Selenium â€” can be replaced with another browser in the code)

### Python Libraries:
Install dependencies using:
```bash
pip install -r requirements.txt
```
---

## ğŸš€ Running the Scrapers:
To run the Work.ua scraper:
```bash
python3.11 -m src.scraper.workua_scraper
```
To run the Robota.ua scraper:
```bash
python3.11 -m src.scraper.robotaua_scraper
```
---
Note: A `main.py` file was considered for simplified execution, but the decision was made to run scrapers individually.

